myapp <- oauth_app("github",
"c5fe1ed743e57cb22599",
"2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
req <- GET("https://api.github.com/rate_limit", config(token = myapp))
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "c5fe1ed743e57cb22599",
secret = "2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/rate_limit", gtoken)
library(jsonlite)
json1 = content(req)
json1
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "c5fe1ed743e57cb22599",
secret = "2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
json1 = content(req)
json1
myapp <- oauth_app("github",
key = "c5fe1ed743e57cb22599",
secret = "2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
stop_for_status(req)
content(req)
install.packages("curl")
install.packages("curl")
library(curl)
oauth_endpoints("github")
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "c5fe1ed743e57cb22599",
secret = "2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
stop_for_status(req)
content(req)
library(httr)
library(httpuv)
library(curl)
oauth_endpoints("github")
myapp <- oauth_app("github",
"c5fe1ed743e57cb22599",
"2e9fe3c75b6212c66ae247125c05ae2e4eeb62b9")
myapp
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
stop_for_status(req)
content(req)
install.pcakages("sqldf")
install.packages("sqldf")
acs <- read.csv(".data/getdata-data-ss06pid.csv", header=T, sep=",")
acs <- read.csv("./data/getdata-data-ss06pid.csv", header=T, sep=",")
acs <- read.csv("./data/getdata-data-ss06pid.csv", header=T, sep=",")
head(acs)
names(acs)
dim(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sqldf("select distinct pwgtp1 from acs")
a=unique(acs$AGEP)
b=sqldf("select distinct pwgtp1 from acs")
dim(a)
length(a)
length(b)
dim(b)
b=sqldf("select distinct AGEP from acs")
length(b)
b
dim(b)
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
?url
con <- url(hurl)
htmlCode <- readLines(con)
close(con)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
head(htmlCode)
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
data <- read.csv("./data/getdata-wksst8110.for", header=T)
head(data)
?read.csv
data <- read.csv("./data/getdata-wksst8110.for",skip=4)
head(data)
data <- read.csv("./data/getdata-wksst8110.for",skip=3)
head(data)
summmarize(data)
summmarise(data)
summarise(data)
summarize(data)
summary(data)
class(data[,5])
dim(data)
data <- fwf("./data/getdata-wksst8110.for")
data <- read.fwf("./data/getdata-wksst8110.for")
data <- read.csv("./data/getdata-wksst8110.for")
head(data)
?read.fwf
data <- read.fwf("./data/getdata-wksst8110.for",widths=5)
head(data)
data <- read.fwf("./data/getdata-wksst8110.for",widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(data)
sum(data[,4])
sum(data[,9])
sum(data[,4])+sum(data[,9])
sum(data[,4])
data=read.csv("./data/getdata-data-ss06hid.csv")
q1=read.table("./data/getdata-data-ss06hid.csv",sep=",",header=TRUE)
q1$ACR==3
ind_cev=which(q1$ACR==3 & q1$AGS==6)
ind_cev
?readJPEG
install.packages(JPEG)
install.packages("jpeg")
library(jpeg)
?jpeg
jeff=readJPEG("./data/getdata-jeff")
jeff=readJPEG("./data/getdata-jeff",native=TRUE)
jeff=readJPEG("./data/getdata-jeff.jpg",native=TRUE)
quantile(jeff, probs = c(0.3, 0.8) )
q3=read.table("./data/getdata-data-GDP.csv",sep=",",header=TRUE)
q1=read.table("./data/getdata-data-ss06hid.csv",sep=",",header=TRUE)
q3=read.table("./data/getdata-data-GDP.csv",sep=",",header=TRUE)
q3=read.table("./data/getdata-data-GDP.csv",sep=",",header=F, skip=5, nrows=190)
q3=read.csv("./data/getdata-data-GDP.csv",header=F, skip=5, nrows=190)
q3a=read.csv("./data/getdata-data-GDP.csv",header=F, skip=5, nrows=190)
q3b=read.csv("./data/getdata-data-EDSTATS_Country.csv",header=TRUE)
intersect(names(q3a),names(q3b))
names(q3b)
names(q3a)
q3a=read.csv("./data/getdata-data-GDP.csv",header=TRUE, skip=4)
intersect(names(q3a),names(q3b))
head(q3a)
q3a=read.csv("./data/getdata-data-GDP.csv",header=TRUE, skip=3)
head(q3a)
intersect(names(q3a),names(q3b))
View(`q3a`)
View(`q3b`)
data=merge(q3a,q3b,by.x=X,by.Y=CountryCode)
data=merge(q3a,q3b,by.x="X",by.Y="CountryCode")
q3a=read.csv("./data/getdata-data-GDP.csv",header=FALSE, skip=4)
data=merge(q3a,q3b,by.x="X",by.Y="CountryCode")
View(`q3a`)
q3a=read.csv("./data/getdata-data-GDP.csv",header=FALSE, skip=5)
data=merge(q3a,q3b,by.x="X",by.Y="CountryCode")
View(`q3a`)
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode")
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode",sort=TRUE)
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode",sort=TRUE)
q3a=read.csv("./data/getdata-data-GDP.csv", header=F, skip=5, nrows=190)
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode",sort=TRUE)
names(q3a)
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode")
names(q3b)
data=merge(q3a,q3b,by.x="V1",by.Y="CountryCode")
?merge
data=merge(x=q3a,y=q3b,by.x="V1",by.Y="CountryCode")
data=merge(x=q3a,y=q3b,by.x="V1",by.Y="CountryCode",all=TRUE)
intersect(names(q3a),names(q3b))
data=merge(x=q3a,y=q3b,by.x="V1",by.Y="CountryCode",sort=TRUE)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
rowNames <- seq(10,200, 2)
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
fed <- read.csv('GDP2.csv')
View(fed)
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
gdp <- read.csv('./data/GDP.csv', header=F, skip=5, nrows=190)
fed <- read.csv('./data/GDP2.csv')
data=merge(x=gdp,y=fed,by.x="V1",by.Y="CountryCode",sort=TRUE)
data=merge(x=gdp,y=fed,by.x="V1",by.Y="CountryCode")
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
data=merge(x=gdp,y=fed,by.x="V1",by.y="CountryCode")
data=merge(x=q3a,y=q3b,by.x="V1",by.y="CountryCode")
q3a=read.csv("./data/getdata-data-GDP.csv",header=FALSE, skip=5)
q3b=read.csv("./data/getdata-data-EDSTATS_Country.csv",header=TRUE)
data=merge(x=q3a,y=q3b,by.x="V1",by.y="CountryCode")
data[with(data, order(-V2) )]
data=[order(desc("V1")),]
order(desc("V1"))
order(data$V2)
?order
order(data$V2,decreasing=TRUE)
intersect(q3a$V1,q3b$CountryCode)
length(intersect(q3a$V1,q3b$CountryCode))
data[13,]
View(data)
q3a=read.csv("./data/getdata-data-GDP.csv",header=FALSE, skip=5,nrows=190)
q3b=read.csv("./data/getdata-data-EDSTATS_Country.csv",header=TRUE)
length(intersect(q3a$V1,q3b$CountryCode))
data=merge(x=q3a,y=q3b,by.x="V1",by.y="CountryCode")
data=data[order(data$V2,decreasing=TRUE),]
data[13,]
View(data)
mean(data[data$Income.Group=='High income: OECD',]$V2)
mean(data[data$Income.Group=='High income: nonOECD',]$V2)
q <- quantile(data$V2, seq(0,1,5))
q
?quantile
seq(0,1,5)
seq(0,1,1/5)
q <- quantile(data$V2, seq(0,1,1/5))
q
q1 <- data$V2 <= 38
xtabs(q1 ~ data$Income.Group)
summary(data$Income.Group)
length(which(data$Income.Group=="Lower middle income" & data$V2 <= 38)
)
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/cameras.csv",method="curl")
download.file(fileUrl,destfile="./data/cameras.csv")
cameraData <- read.csv("./data/cameras.csv")
names(cameraData)
names(cameraData)
tolower(names(cameraData))
splitNames = strsplit(names(cameraData),"\\.")
splitNames[[5]]
splitNames
splitNames[[6]]
mylist <- list(letters = c("A", "b", "c"), numbers = 1:3, matrix(1:25, ncol = 5))
head(mylist)
firstElement <- function(x){x[1]}
sapply(splitNames,firstElement)
fileUrl1 <- "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile="./data/reviews.csv")
download.file(fileUrl2,destfile="./data/solutions.csv")
reviews <- read.csv("./data/reviews.csv")
solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
sub("_","",names(reviews),)
grep("Alameda",cameraData$intersection)
table(grepl("Alameda",cameraData$intersection))
cameraData2 <- cameraData[!grepl("Alameda",cameraData$intersection),]
library(stringr)
nchar("Jeffrey Leek")
cameraData2
nchar("Jeffrey Leek")
substr("Jeffrey Leek",1,7)
paste0("Jeffrey","Leek")
str_trim("Jeff      ")
d1 = date()
d1
d2 = Sys.Date()
d2
format(d2,"%a %b %d")
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960"); z = as.Date(x, "%d%b%Y")
x
as.numeric(z[1]-z[2])
julian(d2)
weekdays(d2)
months(d2)
install.packages("lubridate")
library(lubridate)
ymd("20140108")
ymd_hms("2011-08-03 10:15:03")
ymd_hms("2011-08-03 10:15:03",tz="Pacific/Auckland")
?Sys.timezone
Sys.timezone()
q1=read.csv("getdata-data-ss06hid")
q1=read.csv("./data/getdata-data-ss06hid.csv")
strsplit(names(q1))
strsplit(names(q1),"wgtp")
strsplit(names(q1),"wgtp")[[123]]
q2=read.csv("./data/getdata-data-GDP.csv",header=FALSE, skip=5,nrows=190)
View(`q2`)
this=sub(",","",q2$V5,)
class(this)
head(this)
head(q2$V5)
head(q2$V5)
this=q2$V5
this=sapply(q2$V5,str_trim())
this=sapply(q2$V5,str_trim(x))
this=sapply(q2$V5,function(x) x=str_trim(x))
head(this)
this=sapply(this,function(x) x=str_trim(x))
this=sapply(this,function(x) x=sub(",","",x,))
head(this)
?sub
this=sapply(this,function(x) x=sub(",","",x))
this=sapply(this,function(x) x=sub(",","",x))
this=sapply(this,function(x) x=sub(",","",x))
head(this)
sum(as.numeric(this))
mean(as.numeric(this))
grep("^United",countryNames)
countryNames=q2$V4
grep("^United",countryNames)
length(grep("^United",countryNames))
q4=read.csv("./data/getdata-data-EDSTATS_Country.csv",header=TRUE)
View(`q4`)
apply(q4,2,class)
table(apply(q4,2,class))
q4=apply(q4,2,str_trim)
View(`q4`)
data=merge(x=q3a,y=q3b,by.x="V1",by.y="CountryCode")
data=merge(x=q2,y=q4,by.x="V1",by.y="CountryCode")
View(data)
names(data)
grep(names(data),"year")
grep("year",names(data))
names(data)[grep("year",names(data))]
grep("fiscal",names(data))
grep("fisc",names(data))
grep("fisc",data$Special.Notes)
grep("[Ff]isc",data$Special.Notes)
data$Special.Notes[grep("[Ff]isc",data$Special.Notes)]
fis_notes=grep("[Ff]isc",data$Special.Notes)
fis_notes=grep("[Ff]isc",data$Special.Notes)
grep("[Jj]une",data$Special.Notes[fis_notes])
fisc_June=grep("[Jj]une",data$Special.Notes[fis_notes])
length(fisc_June)
data$Special.Notes[fisc_June)]
data$Special.Notes[fisc_June]
data$Special.Notes[fis_notes][fisc_June]
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
grep("2012",sampleTimes)
length(grep("2012",sampleTimes))
weekdays(sampleTimes(grep("2012",sampleTimes)))
weekdays(sampleTimes[grep("2012",sampleTimes)])
grep("Mon",weekdays(sampleTimes[grep("2012",sampleTimes)]))
length(grep("Mon",weekdays(sampleTimes[grep("2012",sampleTimes)])))
length(grep("2012",sampleTimes))
test_files=list.files("./data/UCI HAR Dataset/test/Inertial Signals")
test_files
train_files=list.files("./data/UCI HAR Dataset/train/Inertial Signals")
train_files
test_path="./data/UCI HAR Dataset/test"
test_files=list.files(paste0(test_path,"/Inertial Signals"))
test_files
test_path="./data/UCI HAR Dataset/test/Inertial Signals"
test_files=list.files(paste0(test_path))
test_files
train_path="./data/UCI HAR Dataset/train/Inertial Signals"
train_path
t1=read.txt(paste0(test_path,"/",test_files[1]))
t1=read.table(paste0(test_path,"/",test_files[1]))
View(`t1`)
X_test_train=read.table("./data/UCI HAR Dataset/test/X_test.txt")
X_test_train=read.table("./data/UCI HAR Dataset/train/X_test.txt")
X_test_train=read.table("./data/UCI HAR Dataset/train/X_test.txt")
X_train=read.table("./data/UCI HAR Dataset/train/X_train.txt")
X_test=read.table("./data/UCI HAR Dataset/test/X_test.txt")
y_train=read.table("./data/UCI HAR Dataset/train/y_train.txt")
y_test=read.table("./data/UCI HAR Dataset/test/y_test.txt")
y=rbind(y_train,y_test)
X=rbind(X_train,X_test)
data=cbind(y,X)
View(data)
hist(y_test)
hist(y_test[,1])
subject_train=read.table("./data/UCI HAR Dataset/train/subject_train.txt")
subject_test=read.table("./data/UCI HAR Dataset/train/subject_test.txt")
subject_test=read.table("./data/UCI HAR Dataset/test/subject_test.txt")
subject=rbind(subject_train,subject_test)
data=cbind(y,subject,X)
names(data)[1]="Activity Labels"
names(data)[2]="Subject Labels"
View(data)
features_info=read.table("./data/UCI HAR Dataset/features_info.txt")
features=read.table("./data/UCI HAR Dataset/features.txt")
View(features)
?grep
mean_features=grep("mean",features[,2])
mean_features
mean_features=grep("std",features[,2])
std_features=grep("std",features[,2])
std_features
keep_inds=c(mean_features,std_features)+2
keep_inds
keep_inds=c(mean_features,std_features)
keep_inds
mean_features
mean_features=grep("mean",features[,2])
std_features=grep("std",features[,2])
keep_inds=c(mean_features,std_features)
keep_inds
keep_inds=order(c(mean_features,std_features)+2)
keep_inds
keep_inds=order(c(mean_features,std_features))
keep_inds
keep_inds=c(mean_features,std_features)+2
keep_inds
keep_inds=keep_inds[order(keep_inds)]
keep_inds
data=data[c(1,2,keep_inds)]
feat_names=features[c(mean_features,std_features),2][order(keep_inds)]
feat_names
keep_inds=c(mean_features,std_features)+2
keep_inds
data=cbind(y,subject,X)
keep_inds=c(mean_features,std_features)
data=data[c(1,2,keep_inds+2)]
feat_names=features[keep_inds,2]
feat_names
keep_inds
keep_inds=c(mean_features,std_features)
data=cbind(y,subject,X)
keep_inds
data=data[c(1,2,keep_inds+2)]
feat_names=features[keep_inds[order(keep_inds)],2]
feat_names
names(data)=c("Activity","Subject",feat_names)
names(data)
feat_names
feat_names=as.character(features[keep_inds[order(keep_inds)],2])
feat_names
names(data)=c("Activity","Subject",feat_names)
names(data)
activity_labels=read.table("./data/UCI HAR Dataset/activity_labels.txt")
activity_labels
data=cbind(y,subject,X)
data=data[c(1,2,keep_inds+2)]
View(data)
class(data[,1])
for (i in 1:nrows(activity_labels)) print(i)
for (i in 1:nrow(activity_labels)) print(i)
class(data[,1])="character"
class(data[,1])
i=1
activity_labels[i,1]
class(activity_labels[i,1])
as.character(activity_labels[i,1])
ind=as.character(activity_labels[i,1])
which(data[,1]==ind)
replacement=as.character(activity_labels[i,2])
replacement
ind=as.character(activity_labels[i,1])
ind
replacement=as.character(activity_labels[i,2])
replacement
rep_ind=which(data[,1]==ind)
rep_ind
data[rep_ind,1]=replacement
View(data)
for (i in 1:nrow(activity_labels)) {
ind=as.character(activity_labels[i,1])
replacement=as.character(activity_labels[i,2])
rep_ind=which(data[,1]==ind)
data[rep_ind,1]=replacement
}
View(data)
names(data)=c("Activity","Subject",feat_names)
View(data)
data2=tbl_df_data
data2=tbl_df(data)
library(dplyr)
data2=tbl_df(data)
data2 %>% group_by("Activity","Subject") %>% summarise(avg=mean)
data2 %>% group_by(Activity,Subject) %>% summarise(avg=mean)
data2 %>% group_by(Activity,Subject) %>% summarise()
tidy_set=data2 %>% group_by(Activity,Subject) %>% summarise()
View(tidy_set)
tidy_set=data2 %>% group_by(Activity,Subject) %>% summarise(mean())
tidy_set=data2 %>% group_by(Activity,Subject) %>% summarise_each()
tidy_set=data2 %>% group_by(Activity,Subject) %>% summarise_each(funs(mean))
View(tidy_set)
?write.table
write.table(tidy_set,file="./data/final_project",row.name=FALSE)
write.table(tidy_set,file="./data/final_project.txt",row.name=FALSE)
jsonData <- fromJSON("http://www.apihub.com/indeed/api/indeed-api")
fromJSON
?fromJSON
library(jsonlite)
jsonData <- fromJSON("http://www.apihub.com/indeed/api/indeed-api")
library(httr)
oauth_endpoints("indeed")
?oauth_endpoints
?GET
?oauth_app
oauth_endpoints("github")
?sign_oauth1.0
?config
?GET
library(httr)
myapp = oauth_app("twitter",
key="kye4vBzDx8HfWlV1zlprpyRyH",secret="ppeQNaUW1yiaF2WJP4paiv8oyzmWbv5dIruWdtLab2Vvm60fVE")
sig = sign_oauth1.0(myapp,
token = "3240115562-T8dGYiz6gPTWpGLCOVBWxoUxbhnFtLh2m0rmfFJ",
token_secret = "OZmG61SyX79hXZ9QMhDNdyn6y0T22fl0TeKNFt4lORxcM")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
sig
?sign_oauth1.0
