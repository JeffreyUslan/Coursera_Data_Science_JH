library(zoo)
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
library(Rcpp)
library(ggplot2)
library(rpart)
data=read.csv("./pml-training.csv")
data=data[,-1]
final_test=read.csv("./pml-testing.csv")
final_test=final_test[,-1]
?randomForest
??randomForest
library(zoo)
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
library(Rcpp)
library(ggplot2)
library(rpart)
library(randomForest)
data=read.csv("./pml-training.csv")
final_test=read.csv("./pml-testing.csv")
data=data[,-1]
final_test=final_test[,-1]
NA_cols=apply(final_test,2,function(x){sum(is.na(x))==length(x)})
NA_vars=names(final_test)[NA_cols]
data=data[,!(names(data) %in% NA_vars)]
final_test=final_test[,!(names(final_test) %in% NA_vars)]
n_nums=sapply(data,is.numeric)
data[,n_nums]=na.approx(data[,n_nums])
n_nums=sapply(final_test,is.numeric)
final_test[,n_nums]=na.approx(final_test[,n_nums])
NZV=nearZeroVar(data, saveMetrics=TRUE)
poor_var=which(NZV$nzv)
rm_vars=c(which(names(data)=="cvtd_timestamp"),poor_var)
data=data[,-rm_vars]
final_test=final_test[,-rm_vars]
classe_ind=which(names(data)=="classe")
n_nums=which(sapply(data,is.numeric))
n_nums=which(sapply(final_test,is.numeric))
final_test=final_test[,c(n_nums)]
data=na.omit(data[,c(n_nums,classe_ind)])
inTrain = createDataPartition(y=data$classe, p = .6)[[1]]
training = data[ inTrain,]
testing = data[-inTrain,]
modFit <- randomForest(classe ~. , data=training)
print(modFit)
modFit
pred=predict(modFit,newdata= training, type = "class")
confusionMatrix(training$classe, pred)
pred=predict(modFit, testing, type = "class")
confusionMatrix(testing$classe,pred)
pred=predict(modFit,newdata= final_test)
pred=predict(modFit,newdata= final_test, type = "class")
dim(training)
dim(final_test)
setdiff(names(training),names(final_test))
setdiff(names(final_test),names(training))
data=read.csv("./pml-training.csv")
final_test=read.csv("./pml-testing.csv")
dim(data)
dim(final_test)
data=data[,-1]
final_test=final_test[,-1]
NA_cols=apply(final_test,2,function(x){sum(is.na(x))==length(x)})
NA_vars=names(final_test)[NA_cols]
NA_vars
NA_cols
sum(NA_cols)
View(final_test)
data=data[,!(names(data) %in% NA_vars)]
final_test=final_test[,!(names(final_test) %in% NA_vars)]
n_nums=sapply(data,is.numeric)
data[,n_nums]=na.approx(data[,n_nums])
n_nums=sapply(final_test,is.numeric)
final_test[,n_nums]=na.approx(final_test[,n_nums])
poor_var=which(NZV$nzv)
rm_vars=c(which(names(data)=="cvtd_timestamp"),poor_var)
rm_vars=c(names(data)=="cvtd_timestamp"),poor_var)
rm_vars=c(names(data)=="cvtd_timestamp",poor_var)
rm_vars
rm_vars=names(data)[c(which(names(data)=="cvtd_timestamp"),poor_var)]
rm_vars
data=data[,!rm_vars]
NA_vars
rm_vars
data=data[,!(names(data) %in% rm_vars)]
final_test=final_test[,!(names(final_test) %in% rm_vars)]
classe_ind=which(names(data)=="classe")
n_nums=which(sapply(data,is.numeric))
data=na.omit(data[,c(n_nums,classe_ind)])
n_nums=which(sapply(final_test,is.numeric))
final_test=final_test[,c(n_nums)]
inTrain = createDataPartition(y=data$classe, p = .6)[[1]]
training = data[ inTrain,]
testing = data[-inTrain,]
modFit <- randomForest(classe ~. , data=training)
print(modFit)
pred=predict(modFit,newdata= training, type = "class")
confusionMatrix(training$classe, pred)
pred=predict(modFit, testing, type = "class")
confusionMatrix(testing$classe,pred)
pred=predict(modFit,newdata= final_test, type = "class")
# q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
modRF=train(y~.,data=vowel.train,method="rf",prox=TRUE)
predRf=predict(modRF,newdata=vowel.test)
confusionMatrix(vowel.test$y,predRf)
modgbm=train(y~.,data=vowel.train,method="gbm",verbose=FALSE)
predGBM=predict(modgbm,newdata=vowel.test)
confusionMatrix(vowel.test$y,predGBM)
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
read.xls(file.choose())
install.package("xlsx")
install.packages("xlsx")
library(xlsx)
read.xls(file.choose())
read.xlsx(file.choose())
install.packages("rJava")
library(xlsx)
library(rJava)
library(xlsx)
library(rJava)
library(rJava)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45')
library(rJava)
system("java -version")
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\bin\\')
library(rJava)
Sys.setenv(JAVA_HOME='C:\Program Files (x86)\Java\jre1.8.0_45\bin\')
Sys.setenv(JAVA_HOME='C:/Program Files (x86)/Java/jre1.8.0_45/')
library(rJava)
Sys.getenv('JAVA')
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45')
install()
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\')
library(rJava)
library(rJava)
install()
Sys.getenv('JAVA')
Sys.setenv(JAVA='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\')
Sys.getenv('JAVA')
library(rJava)
install()
Sys.getenv('JAVA')
install()
install.packages("javaOnloadFailed")
library("javaOnloadFailed")
install()
library(rJava)
Sys.setenv(JAVA='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\')
Sys.getenv('JAVA')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_45\\')
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_45\\')
library(rJava)
?install
# q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
modRF=train(y~.,data=vowel.train,method="rf",prox=TRUE)
predRf=predict(modRF,newdata=vowel.test)
confusionMatrix(vowel.test$y,predRf)
modgbm=train(y~.,data=vowel.train,method="gbm",verbose=FALSE)
predGBM=predict(modgbm,newdata=vowel.test)
confusionMatrix(vowel.test$y,predGBM)
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
?confusionMatrix
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
modRF=train(y~.,data=vowel.train,method="rf",prox=TRUE)
predRf=predict(modRF,newdata=vowel.test)
confusionMatrix(vowel.test$y,predRf)
modgbm=train(y~.,data=vowel.train,method="gbm",verbose=FALSE)
predGBM=predict(modgbm,newdata=vowel.test)
confusionMatrix(vowel.test$y,predGBM)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
print(paste(c1, c2, c3, c4))
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T) # Cement
library(lubridate)  # For year() function below
library(forecast)
install.packages("forecast")
library(forecast)
dat <- read.csv("./gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
prop.table(table(predComb$in95))[2]
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength, p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(325)
fit <- svm(CompressiveStrength ~., data=training)
?SVM
?svm
fit <- train(CompressiveStrength ~. data=training, method="svmRadial")
fit <- svm(CompressiveStrength ~., data=training)
pred <- predict(fit, testing)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
acc[2] # RMSE 6.71500
library(zoo)
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
library(Rcpp)
library(ggplot2)
library(randomForest)
library(rpart)
data=read.csv("./pml-training.csv")
data=data[,-1]
final_test=read.csv("./pml-testing.csv")
final_test=final_test[,-1]
NA_cols=apply(final_test,2,function(x){sum(is.na(x))==length(x)})
NA_vars=names(final_test)[NA_cols]
data=data[,!(names(data) %in% NA_vars)]
n_nums=sapply(data,is.numeric)
data[,n_nums]=na.approx(data[,n_nums])
NZV=nearZeroVar(data, saveMetrics=TRUE)
poor_var=which(NZV$nzv)
rm_vars=c(which(names(data)=="cvtd_timestamp"),poor_var)
data=data[,-rm_vars]
classe_ind=which(names(data)=="classe")
n_nums=which(sapply(data,is.numeric))
data2=na.omit(data[,c(n_nums,classe_ind)])
inTrain = createDataPartition(y=data2$classe, p = .6)[[1]]
training = data2[ inTrain,]
testing = data2[-inTrain,]
?rpart
modFitTree <- train(classe ~ ., method = "rpart", data = training)
modFit <- randomForest(classe ~. , data=training)
?createFolds
flds <- createFolds(y=data2$classe, k = 10, list = TRUE, returnTrain = FALSE)
str(flds)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("Hmisc")
install.packages("Rcpp")
install.packages("rpart")
install.packages("randomForest")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("e1701")
install.packages("e1071")
