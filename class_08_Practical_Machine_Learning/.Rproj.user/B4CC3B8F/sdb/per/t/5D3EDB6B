{
    "contents" : "\n\n# q1\nlibrary(caret)\nlibrary(ElemStatLearn)\ndata(vowel.train)\ndata(vowel.test) \n\nvowel.train$y=as.factor(vowel.train$y)\nvowel.test$y=as.factor(vowel.test$y)\nset.seed(33833)\n\nmodRF=train(y~.,data=vowel.train,method=\"rf\",prox=TRUE)\npredRf=predict(modRF,newdata=vowel.test)\nconfusionMatrix(vowel.test$y,predRf)\n\n\nmodgbm=train(y~.,data=vowel.train,method=\"gbm\",verbose=FALSE)\npredGBM=predict(modgbm,newdata=vowel.test)\nconfusionMatrix(vowel.test$y,predGBM)\n\n\npred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)\n\naccuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)\naccuracy\n\n\n\n#q2\nlibrary(caret)\nlibrary(gbm)\nset.seed(3433)\nlibrary(AppliedPredictiveModeling)\ndata(AlzheimerDisease)\nadData = data.frame(diagnosis,predictors)\ninTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]\ntraining = adData[ inTrain,]\ntesting = adData[-inTrain,]\nset.seed(62433)\nfitRf <- train(diagnosis ~ ., data=training, method=\"rf\")\nfitGBM <- train(diagnosis ~ ., data=training, method=\"gbm\")\nfitLDA <- train(diagnosis ~ ., data=training, method=\"lda\")\npredRf <- predict(fitRf, testing)\npredGBM <- predict(fitGBM, testing)\npredLDA <- predict(fitLDA, testing)\npred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)\n\nfit <- train(diagnosis ~., data=pred, method=\"rf\")\npredFit <- predict(fit, testing)\nc1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]\nc2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]\nc3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]\nc4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]\nprint(paste(c1, c2, c3, c4)) \n\n\n#q3\nset.seed(3523)\nlibrary(AppliedPredictiveModeling)\nlibrary(elasticnet)\ndata(concrete)\ninTrain <- createDataPartition(concrete$CompressiveStrength, \n                               p=3/4)[[1]]\ntraining <- concrete[inTrain, ]\ntesting <- concrete[-inTrain, ]\nset.seed(233)\nfit <- train(CompressiveStrength ~ ., data=training, method=\"lasso\")\nfit\nplot.enet(fit$finalModel, xvar=\"penalty\", use.color=T) # Cement\n\n\n#q4\nlibrary(lubridate)  \nlibrary(forecast)\ndat <- read.csv(\"./gaData.csv\")\ntraining <- dat[year(dat$date) < 2012, ]\ntesting <- dat[(year(dat$date)) > 2011, ]\ntstrain <- ts(training$visitsTumblr)\nfit <- bats(tstrain)\nfit\npred <- forecast(fit, level=95, h=dim(testing)[1])\nnames(data.frame(pred))\npredComb <- cbind(testing, data.frame(pred))\nnames(testing)\nnames(predComb)\npredComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) & \n  (predComb$visitsTumblr < predComb$Hi.95)\n\nprop.table(table(predComb$in95))[2] \n\n\n#Q5\nset.seed(3523)\nlibrary(AppliedPredictiveModeling)\nlibrary(e1071)\ndata(concrete)\ninTrain <- createDataPartition(concrete$CompressiveStrength, p=3/4)[[1]]\ntraining <- concrete[inTrain, ]\ntesting <- concrete[-inTrain, ]\nset.seed(325)\nfit <- svm(CompressiveStrength ~., data=training)\n\npred <- predict(fit, testing)\nacc <- accuracy(pred, testing$CompressiveStrength)\nacc\n\n",
    "created" : 1432751263676.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "671727359",
    "id" : "5D3EDB6B",
    "lastKnownWriteTime" : 1432660411,
    "path" : "~/Coursera_Data_Science_JH/class_08_Practical_Machine_Learning/Quiz_4.R",
    "project_path" : "Quiz_4.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}