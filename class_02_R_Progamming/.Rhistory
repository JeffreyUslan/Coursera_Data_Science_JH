total=base*crit,total
nbase=424;pbase=26500
ncrit=1.7;pcrit=73500
narrow=4*.65;parrow=135000
dps(nbase,crit,arrow,total,pbase)
dps(base,ncrit,arrow,total,pcrit)
dps(base,crit,narrow,total,parrow)
dps=function(base,crit,arrow,total,price){
total2=base*crit*arrow
dps=(total2-total)/price
return(dps)
}
base=420
crit=1.65
arrow=4*.6
total=base*crit*total
nbase=424;pbase=26500
ncrit=1.7;pcrit=73500
narrow=4*.65;parrow=135000
dps(nbase,crit,arrow,total,pbase)
dps(base,ncrit,arrow,total,pcrit)
dps(base,crit,narrow,total,parrow)
dps=function(base,crit,arrow,total,price){
total2=base*crit*arrow
dps=(total2-total)/price
return(dps)
}
base=420
crit=1.65
arrow=4*.6
total=base*crit*arrow
nbase=424;pbase=26500
ncrit=1.7;pcrit=73500
narrow=4*.65;parrow=135000
dps(nbase,crit,arrow,total,pbase)
dps(base,ncrit,arrow,total,pcrit)
dps(base,crit,narrow,total,parrow)
dps=function(base,crit,arrow,total,price){
total2=base*crit*arrow
dps=(total2-total)/price
return(dps)
}
base=424
crit=1.7
arrow=5*.6
total=base*crit*arrow
nbase=428;pbase=30700
ncrit=1.75;pcrit=90000
narrow=5*.65;parrow=245000
dps(nbase,crit,arrow,total,pbase)
dps(base,ncrit,arrow,total,pcrit)
dps(base,crit,narrow,total,parrow)
dps(base,crit,narrow,total,parrow)
nbase=428;pbase=30700
ncrit=1.76;pcrit=106500
narrow=5*.65;parrow=245000
dps(nbase,crit,arrow,total,pbase)
dps(base,ncrit,arrow,total,pcrit)
dps(base,crit,narrow,total,parrow)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(bone)
plot(bone$age,bone$spnbmd,pch=19,col=((bone$gender=="male")+1))
data(marketing)
plot(bone$age,bone$spnbmd,pch=19,col=((bone$gender=="male")+1))
boxplot(marketing$Income ~ marketing$Marital,col="grey",xaxt="n",ylab="Income",xlab="")
axis(side=1,at=1:5,labels=c("Married","Living together/not married","Divorced or separated","Widowed","Nevermarried"),las=2)
library(datasets)
data(iris)
irisSubset=iris[,1:4]
irisDist=dist(irisSubset)
View(irisSubset)
head(irisDist)
hclust(irisDist)
plot(hclust(irisDist))
test=read.csv("https://spark-public.s3.amazonaws.com/dataanalysis/quiz3question4.csv"")
test=read.csv("https://spark-public.s3.amazonaws.com/dataanalysis/quiz3question4.csv")
class(test)
View(test)
plot(test)
plot(test[,2],test[,3])
x=test[,2]
y=test[,3]
?kmeans
dataf=data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=2)
kmeansObj <- kmeans(dataf,centers=2)
names(kmeansObj)
par(mar=rep(0.2,4))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
data(zip.train)
View(zip.train)
kmeansObj <- kmeans(dataf,centers=3)
names(kmeansObj)
par(mar=rep(0.2,4))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
im = zip2image(zip.train,3)
image(im)
im = zip2image(zip.train,8)
image(im)
im8 = zip2image(zip.train,8)
im8 = zip2image(zip.train,8)
im18 = zip2image(zip.train,18)
image(im8)
image(im18)
im8svd=svd(im8)
im18svd=svd(im18)
cumsum(im8svd$d)
im8svd$d
cumsum(im8svd$d)/sum(im8svd$d)
im8 = zip2image(zip.train,8)
im8svd=svd(im8)
cumsum(im8svd$d)/sum(im8svd$d)
im18 = zip2image(zip.train,18)
im18svd=svd(im18)
cumsum(im18svd$d)/sum(im18svd$d)
cumsum(im8svd$d^2)/sum(im8svd$d^2)
cumsum(im18svd$d^2)/sum(im18svd$d^2)
image(im18)
name(dad)
names(dad)
dad=read.csv(file.choose())
dad=read.csv(file.choose())
View(dad)
dad=dad[,-16]
View(dad)
dad=dad[-c(1,2),]
dad=read.csv(file.choose())
dad=dad[,-c(1,2,7,16)]
plot(dad)
length(which(dad$GENDER1==GENDER2))
length(which(dad$GENDER1==dad$GENDER2))
gen_inc=rbind(data.frame(dad$GENDER1,dad$INC1),data.frame(dad$GENDER2,dad$INC2))
gen_inc=data.frame(dad$GENDER1,dad$INC1)#,data.frame(dad$GENDER2,dad$INC2))
View(gen_inc)
gen_inc=rbind(as.matrix(dad$GENDER1,dad$INC1),as.matrix(data.frame(dad$GENDER2,dad$INC2)))
gen=c(dad$GENDER1,dad$GENDER2)
inc=c(dad$INC1,dad$INC2)
gen_inc=data.frame(gen,inc)
View(gen_inc)
summary(gen_inc[which(gen_inc[,1]==1),2])
summary(gen_inc[which(gen_inc[,1]==2),2])
dad=read.csv(file.choose())
dad=read.csv(file.choose())
dad=dad[,-c(7,16)]
View(dad)
gen=c(dad$GENDER1,dad$GENDER2)
inc=c(dad$INC1,dad$INC2)
occ=c(dad[,1,dad[,2]])
occ=c(dad[,1],dad[,2])
stud=data.frame(gen,inc,occ)
t.test(dad$AGE1,mu=34)
t.test(dad$AGE1,dad$AGE2,paired=TRUE)
lm(dad$AGE1~dad$AGE2)
length(which(dad$HAPPY>=4))/400
t.test(dad$L,dad$GENDER1)
t.test(dad$AGE1,mu=34)
chisq.test(dad$REGION,dad$FCOMFORT)
oneway.test(dad$INC1~as.factor(dad$RELAT),var.equal=TRUE)
lmObj=lm(dad$INC1~as.factor(dad$GENDER1)+as.factor(dad$MSTAT)+as.factor(dad$GENDER1)*as.factor(dad$MSTAT))
anova(lmObj)
lmObj=lm(stud[,2]~as.factor(stud[,1]))
anova(lmObj)
t.test(stud[,2],as.factor(stud[,1]))
t.test(stud[which(stud[,1]==1),2],stud[which(stud[,1]==2),2])
unique(dad[,1])
length(unique(dad[,1]))
length(unique(dad[,2]))
length(unique(c(dad[,1],dad[,2])))
t.test(stud[which(stud[,1]==1),2],stud[which(stud[,1]==2),2])
lmObj=lm(stud[,2]~as.factor(stud[,1]))
anova(lmObj)
summary(lmObj)
dad=read.csv(file.choose())
gen=c(dad$GENDER1,dad$GENDER2)
inc=c(dad$INC1,dad$INC2)
edu=c(dad$EDUC1,dad$EDUC2)
reg=c(dad$REGION,dad$REGION)
stud=data.frame(gen,inc,edu,reg)
install.packages("caret")
library(caret)
library(spam)
install.packages("spam")
library(spam)
install.packages("kernlab")
library(kernlab)
? spam
data(spam)
View(spam)
library(kernlab) ; data(spam) ; set.seed(333)
smallSpam=spam[sample(dim(spam)[1],size=10),]
spamLabel=smallSpam$type=="spam"*1+1
spamLabel=smallSpam$type=="spam"
spamLabel=smallSpam$type=="spam"
plot(smallSpam$capitalAve,col=spamLabel)
smallSpam=spam[sample(dim(spam)[1],size=10),]
spamLabel=smallSpam$type=="spam"
spamLabel=(smallSpam$type=="spam")*1 +1
plot(smallSpam$capitalAve,col=spamLabel)
install.packages("caret")
library(caret)
library(spam)
library(kernlab) ; data(spam) ; set.seed(333)
install.packages("caret")
library(caret)
install.packages("spam")
install.packages("kernlab")
library(spam)
library(kernlab) ; data(spam) ; set.seed(333)
smallSpam=spam[sample(dim(spam)[1],size=10),]
spamLabel=(smallSpam$type=="spam")*1 +1
plot(smallSpam$capitalAve,col=spamLabel)
library(caret)
library(spam)
library(kernlab) ; data(spam) ; set.seed(333)
smallSpam=spam[sample(dim(spam)[1],size=10),]
spamLabel=(smallSpam$type=="spam")*1 +1
plot(smallSpam$capitalAve,col=spamLabel)
library(caret)
library(ggplot2)
inTrain = createDataPartition(y=iris$Species, p = .1,list=FALSE)
training = adData[ inTrain,]
testing = adData[-inTrain,]
training = iris[ inTrain,]
testing = iris[-inTrain,]
modFit=train(Species~.,method="rpart",data=training)
library(caret)
library(ggplot2)
data(iris)
inTrain = createDataPartition(y=iris$Species, p = .1,list=FALSE)
training = iris[ inTrain,]
testing = iris[-inTrain,]
modFit=train(Species~.,method="rpart",data=training)
install.packages('e1071', dependencies=TRUE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
levels(segementationOriginal$Class)
summry(segementationOriginal$Class)
summary(segementationOriginal$Class)
summary(segmentationOriginal)
training = segmentationOriginal[which(segmentationOriginal$Case=="Train")]
training = segmentationOriginal[which(segmentationOriginal$Case=="Train"),]
testing = segmentationOriginal[which(segmentationOriginal$Case=="Test"),]
set.seed(125)
names(segmentationOriginal)
modFit=train(CART~.,method="rpart",data=training)
modFit=train(Class~.,method="rpart",data=training)
summary(modFit)
print(modFit$finalModel)
summary(segmentationOriginal$Class)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("KernSmooth")
library(KernSmooth)
source('~/coursera/Practical_Machine_Learning/Quiz_1.R')
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
splitOn <- cut2(training$Age, g = 4)
splitOn <- mapvalues(splitOn,
from = levels(factor(splitOn)),
to = c("red", "blue", "yellow", "green"))
?mapvalues
library(plyr)
splitOn <- mapvalues(splitOn,from = levels(factor(splitOn)),
to = c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col = splitOn)
splitOn <- cut2(training$FlyAsh, g = 4)
splitOn <- mapvalues(splitOn,from = levels(factor(splitOn)),
to = c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col = splitOn)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
summarize(training)
hist(training$Sperplasticizer)
hist(training$SperPlasticizer)
names(training)
hist(training$Superplasticizer)
summarize(training$Superplasticizer)
summary(training$Superplasticizer)
log(0)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_variables <- grep("^IL", names(training), value = TRUE)
preProc <- preProcess(training[, IL_variables], method = "pca", thresh = 0.9)
preProc
preProc <- preProcess(training[, IL_variables], method = "pca", thresh = 0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
library(plyr)
data(AlzheimerDisease)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
splitOn <- cut2(training$FlyAsh, g = 4)
splitOn <- mapvalues(splitOn,from = levels(factor(splitOn)),
plot(training$CompressiveStrength, col = splitOn)
)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_variables <- grep("^IL", names(training), value = TRUE)
preProc <- preProcess(training[, IL_variables], method = "pca", thresh = 0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
hist(training$Superplasticizer)
summary(training$Superplasticizer)
log(0)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
ibrary(AppliedPredictiveModeling)
library(caret)
library(rpart)
library(caret)
install.packages(rattle)
install.packages("rattle")
library(AppliedPredictiveModeling)
library(rattle)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = train)
modFit$finalModel
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
library(randomForest)
model <- train(Area ~ ., data = olive, method = "rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
x <- 4L
x
x+.5
x <- c(1,3, 5)
y <- c(3, 2, 10)
cbind(x, y)
read.csv(fike.choose())
read.csv(file.choose())
data=read.csv(file.choose())
View(data)
dim(data)
length(is.na(data$Ozone))
sum(is.na(data$Ozone))
mean(na.omit(data$Ozone))
mean(data$Solar.R[Ozone>31 & Temp>90])
mean(data$Solar.R[which(data$Ozone>31 & data$Temp>90)])
mean(data$Temp[which(data$Month==6)])
max(data$Ozone[which(data$Month==6)])
max(na.omit(data$Ozone[which(data$Month==6)]))
max(na.omit(data$Ozone[which(data$Month==5)]))
set.seed(1)
rpois(5, 2)
?rnorm
dnorm(1)
?rpois
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
x
e
plot(y)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
system.time()
?system.time
y
x
e
summaryRprof()
setwd("~/coursera/R_programing")
dir.create("data")
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile="./data/cameras.csv", method="curl")
download.file(fileUrl, destfile="./data/cameras.csv")
